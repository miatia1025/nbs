{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @markdown # 遊び方\n",
        "# @markdown 必要なものをフォームに入力しながら上から順にセルを実行していく\n",
        "\n",
        "# @markdown # 結果\n",
        "# @markdown 文章の類似度が図れる！！！！ワザップ並み感\n",
        "\n",
        "print(\"うんち\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HDn2A7txNvsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJqNotg0LG96"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown # 📥 installing requirements\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown 必要なものをcolabのPCにインストールするところ<br>\n",
        "# @markdown google colabのPCの仮想環境が汚れるだけなので、安心してインストールできる\n",
        "\n",
        "!pip install transformers\n",
        "!pip install fugashi\n",
        "!pip install ipadic\n",
        "!pip install icecream"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown # 🌱 create [calc_embedding] function\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ここでは文章を数値化する関数 **calc_embedding** を定義してある。<br>\n",
        "# @markdown あくまで定義だけして、あとで使う\n",
        "\n",
        "# tokenize\n",
        "# ref: https://note.com/hajime_pol/n/n5d3192362111\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "from transformers import BertJapaneseTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "model_bert = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', output_hidden_states=True)\n",
        "model_bert.eval()\n",
        "\n",
        "def calc_embedding(text):\n",
        "  bert_tokens = tokenizer.tokenize(text)\n",
        "  ids = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + bert_tokens[:126] + [\"[SEP]\"])\n",
        "  tokens_tensor = torch.tensor(ids).reshape(1, -1)\n",
        "  with torch.no_grad():\n",
        "    output = model_bert(tokens_tensor)\n",
        "  return output[1].numpy()[0]"
      ],
      "metadata": {
        "id": "iXNIy5BzLXwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown # 📅 calculate dot product between A and B\n",
        "# @markdown <hr><br>\n",
        "\n",
        "# @markdown A, Bに好きな文字を突っ込んで、両方を calc_embedding 関数で数値化。<br>\n",
        "# @markdown その後内積という簡単な計算を行ってコサイン類似度の比較を行う<br><br>\n",
        "# @markdown <hr>\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "A = \"\\u304F\\u3045\\uFF5E\\u75B2\\u308C\\u307E\\u3057\\u305Fw \\u3053\\u308C\\u306B\\u3066\\u5B8C\\u7D50\\u3067\\u3059\\uFF01 \\u5B9F\\u306F\\u3001\\u30CD\\u30BF\\u30EC\\u30B9\\u3057\\u305F\\u3089\\u4EE3\\u884C\\u306E\\u8A71\\u3092\\u6301\\u3061\\u304B\\u3051\\u3089\\u308C\\u305F\\u306E\\u304C\\u59CB\\u307E\\u308A\\u3067\\u3057\\u305F \\u672C\\u5F53\\u306F\\u8A71\\u306E\\u30CD\\u30BF\\u306A\\u304B\\u3063\\u305F\\u306E\\u3067\\u3059\\u304C\\u2190 \\u3054\\u539A\\u610F\\u3092\\u7121\\u99C4\\u306B\\u3059\\u308B\\u308F\\u3051\\u306B\\u306F\\u884C\\u304B\\u306A\\u3044\\u306E\\u3067\\u6D41\\u884C\\u308A\\u306E\\u30CD\\u30BF\\u3067\\u6311\\u3093\\u3067\\u307F\\u305F\\u6240\\u5B58\\u3067\\u3059w \\u4EE5\\u4E0B\\u3001\\u307E\\u3069\\u304B\\u9054\\u306E\\u307F\\u3093\\u306A\\u3078\\u306E\\u30E1\\u30C3\\u30BB\\u30B8\\u3092\\u3069\\u305E  \\u307E\\u3069\\u304B\\u300C\\u307F\\u3093\\u306A\\u3001\\u898B\\u3066\\u304F\\u308C\\u3066\\u3042\\u308A\\u304C\\u3068\\u3046 \\u3061\\u3087\\u3063\\u3068\\u8179\\u9ED2\\u306A\\u3068\\u3053\\u308D\\u3082\\u898B\\u3048\\u3061\\u3083\\u3063\\u305F\\u3051\\u3069\\u30FB\\u30FB\\u30FB\\u6C17\\u306B\\u3057\\u306A\\u3044\\u3067\\u306D\\uFF01\\u300D  \\u3055\\u3084\\u304B\\u300C\\u3044\\u3084\\u30FC\\u3042\\u308A\\u304C\\u3068\\uFF01 \\u79C1\\u306E\\u304B\\u308F\\u3044\\u3055\\u306F\\u4E8C\\u5341\\u5206\\u306B\\u4F1D\\u308F\\u3063\\u305F\\u304B\\u306A\\uFF1F\\u300D  \\u30DE\\u30DF\\u300C\\u898B\\u3066\\u304F\\u308C\\u305F\\u306E\\u306F\\u5B09\\u3057\\u3044\\u3051\\u3069\\u3061\\u3087\\u3063\\u3068\\u6065\\u305A\\u304B\\u3057\\u3044\\u308F\\u306D\\u30FB\\u30FB\\u30FB\\u300D  \\u4EAC\\u5B50[1]\\u300C\\u898B\\u3066\\u304F\\u308C\\u3042\\u308A\\u304C\\u3068\\u306A\\uFF01 \\u6B63\\u76F4\\u3001\\u4F5C\\u4E2D\\u3067\\u8A00\\u3063\\u305F\\u79C1\\u306E\\u6C17\\u6301\\u3061\\u306F\\u672C\\u5F53\\u3060\\u3088\\uFF01\\u300D  \\u307B\\u3080\\u3089\\u300C\\u30FB\\u30FB\\u30FB\\u3042\\u308A\\u304C\\u3068\\u300D\\uFF8C\\uFF67\\uFF7B  \\u3067\\u306F\\u3001  \\u307E\\u3069\\u304B\\u3001\\u3055\\u3084\\u304B\\u3001\\u30DE\\u30DF\\u3001\\u4EAC\\u5B50\\u3001\\u307B\\u3080\\u3089\\u3001\\u4FFA\\u300C\\u7686\\u3055\\u3093\\u3042\\u308A\\u304C\\u3068\\u3046\\u3054\\u3056\\u3044\\u307E\\u3057\\u305F\\uFF01\\u300D  \\u7D42  \\u307E\\u3069\\u304B\\u3001\\u3055\\u3084\\u304B\\u3001\\u30DE\\u30DF\\u3001\\u4EAC\\u5B50\\u3001\\u307B\\u3080\\u3089\\u300C\\u3063\\u3066\\u3001\\u306A\\u3093\\u3067\\u4FFA\\u304F\\u3093\\u304C\\uFF01\\uFF1F \\u6539\\u3081\\u307E\\u3057\\u3066\\u3001\\u3042\\u308A\\u304C\\u3068\\u3046\\u3054\\u3056\\u3044\\u307E\\u3057\\u305F\\uFF01\\u300D  \\u672C\\u5F53\\u306E\\u672C\\u5F53\\u306B\\u7D42\\u308F\\u308A\" # @param {type:\"string\"}\n",
        "B = \"\\u521D\\u30AB\\u30AD\\u30B3\\u2026\\u3069\\u3082\\u2026  \\u4FFA\\u307F\\u305F\\u3044\\u306A\\u4E2D3\\u3067\\u30B0\\u30ED\\u898B\\u3066\\u308B\\u8150\\u308C\\u91CE\\u90CE\\u3001\\u4ED6\\u306B\\u3001\\u3044\\u307E\\u3059\\u304B\\u3063\\u3066\\u3044\\u306D\\u30FC\\u304B\\u3001\\u306F\\u306F  \\u4ECA\\u65E5\\u306E\\u30AF\\u30E9\\u30B9\\u306E\\u4F1A\\u8A71 \\u3042\\u306E\\u6D41\\u884C\\u308A\\u306E\\u66F2\\u304B\\u3063\\u3053\\u3044\\u3044\\u3000\\u3068\\u304B\\u3000\\u3042\\u306E\\u670D\\u307B\\u3057\\u3044\\u3000\\u3068\\u304B \\u307E\\u3001\\u305D\\u308C\\u304C\\u666E\\u901A\\u3067\\u3059\\u308F\\u306A  \\u304B\\u305F\\u3084\\u4FFA\\u306F\\u96FB\\u5B50\\u306E\\u7802\\u6F20\\u3067\\u6B7B\\u4F53\\u3092\\u898B\\u3066\\u3001\\u545F\\u304F\\u3093\\u3059\\u308F it\\u2019a true wolrd\\uFF0E\\u72C2\\u3063\\u3066\\u308B\\uFF1F\\u305D\\u308C\\u3001\\u8A89\\u3081\\u8A00\\u8449\\u306D\\u3002  \\u597D\\u304D\\u306A\\u97F3\\u697D\\u3000eminem \\u5C0A\\u656C\\u3059\\u308B\\u4EBA\\u9593\\u3000\\u30A2\\u30C9\\u30EB\\u30D5\\u30FB\\u30D2\\u30C8\\u30E9\\u30FC\\uFF08\\u8650\\u6BBA\\u884C\\u70BA\\u306FNO\\uFF09  \\u306A\\u3093\\u3064\\u3063\\u3066\\u308B\\u9593\\u306B4\\u6642\\u3063\\u3059\\u3088(\\u7B11)\\u3000\\u3042\\uFF5E\\u3042\\u3001\\u7FA9\\u52D9\\u6559\\u80B2\\u306E\\u8F9B\\u3044\\u3068\\u3053\\u306D\\u3001\\u3053\\u308C\" # @param {type:\"string\"}\n",
        "A_emb = calc_embedding(A)\n",
        "B_emb = calc_embedding(B)\n",
        "\n",
        "cos_sim = np.dot(A_emb, B_emb) / (np.linalg.norm(A_emb) * np.linalg.norm(B_emb))\n",
        "\n",
        "print(cos_sim)"
      ],
      "metadata": {
        "id": "nedJ165qPFEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown # 😎 garbarge\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown 上の処理の中でA_emb, B_embという変数が使われていて、<br>\n",
        "# @markdown これにはA, Bに入力したテキストが数値化されたものが入っている。<br><br>\n",
        "# @markdown しかしそれを `print(A_emb)` などしても、およそ人間にはわからない数値の羅列が出てくる。<br>\n",
        "# @markdown これはPC側がどのようなインプットを受け取ったのかを数値で認識するための形式で、人間に理解できるものではない。<br>\n",
        "# @markdown しかしPCからすれば、ここに大量の情報が詰まっており、これさえあれば一目で現在の状況がわかるにまで至る。<br><br>\n",
        "# @markdown このPCが理解するために数値に落とし込まれたメディア(文章、画像、音声など)のことを、<br>\n",
        "# @markdown  **Embedding(埋め込み)** という<br>\n",
        "\n",
        "# icで表示しようと思ったけどなんか重かったのでやめ\n",
        "# from icecream import ic\n",
        "\n",
        "print(f\"A_emb = {A_emb}\")\n",
        "print(f\"B_emb = {B_emb}\")"
      ],
      "metadata": {
        "id": "lTZZodJtQ08i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}